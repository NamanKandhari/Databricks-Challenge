{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1846ede0-59ab-433e-97c3-07dd22f288f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use catalog maven_catalog;\n",
    "use schema bronze_schema;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa549715-3b32-4e0f-8a76-3536ae83aac0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Load Bronze Layer Data\n",
    "spark.sql(\"USE CATALOG maven_catalog\")\n",
    "bronze_df = spark.read.format(\"delta\").table(\"maven_catalog.maven_market_landing.customers\")\n",
    "\n",
    "display(bronze_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c48838cd-c01e-4f85-ae25-08e49783b0cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5be0fb9d-4c00-4f96-9b73-1d1d63c9cd41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 2. Data Cleaning (Silver Preparation)\n",
    "\n",
    "# Remove null users\n",
    "clean_df = bronze_df.filter(col(\"customer_id\").isNotNull())\n",
    "\n",
    "# Remove duplicates\n",
    "clean_df = clean_df.dropDuplicates([\"customer_id\", \"first_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "305855cb-d310-4d08-a42d-dc1b39a5111c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Create User-Level Feature Table\n",
    "from pyspark.sql.functions import count, countDistinct, max, avg, sum\n",
    "\n",
    "feature_df = bronze_df.groupBy(\"customer_id\").agg(\n",
    "    # Demographic & Financial Featuress\n",
    "    avg(\"yearly_income\").alias(\"avg_yearly_income\"),\n",
    "    max(\"total_children\").alias(\"total_children\"),\n",
    "    max(\"num_children_at_home\").alias(\"children_at_home\"),\n",
    "    \n",
    "    # Metadata and Categorical Features\n",
    "    max(\"_fivetran_synced\").alias(\"last_data_sync\"),\n",
    "    countDistinct(\"occupation\").alias(\"unique_occupations\"),\n",
    "    \n",
    "    # Validation flag (checking if multiple records exist per ID)\n",
    "    count(\"*\").alias(\"record_count\")\n",
    ")\n",
    "\n",
    "display(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6676984e-fee7-475d-a18d-89f692133255",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Feature Quality Validation\n",
    "from pyspark.sql.functions import col, count, when\n",
    "\n",
    "# Check for duplicates using the actual customer_id column\n",
    "dup_check = feature_df.filter(col(\"record_count\") > 1)\n",
    "print(f\"Duplicate Customer IDs Found: {dup_check.count()}\")\n",
    "\n",
    "# Check for nulls across the new feature set\n",
    "null_counts = feature_df.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c) for c in feature_df.columns\n",
    "])\n",
    "\n",
    "display(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c15d64c9-3d22-45ff-b154-6a8d816452d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 5. Save as Silver Layer (Delta Table)\n",
    "\n",
    "feature_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"silver.user_features\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6292187986820822,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Day 2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
